{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b3c472c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19f05d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function converst audio file to spectrogram\n",
    "import librosa\n",
    "import librosa.display\n",
    "from PIL import Image\n",
    "def audio_to_spectrogram(audio_path, output_path):\n",
    "    y, sr = librosa.load(audio_path)\n",
    "    spect = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    spect = librosa.power_to_db(spect, ref=np.max)\n",
    "    \n",
    "    inverted_spect = spect.max() - spect\n",
    "    \n",
    "    plt.figure(figsize=(2.24, 2.24))\n",
    "    librosa.display.specshow(inverted_spect, sr=sr, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(output_path, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "    \n",
    "    image = Image.open(output_path)\n",
    "#     image = image.resize((64, 64), Image.LANCZOS)  # Resize to 64x64 pixels\n",
    "    image.save(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a430d97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub.silence import detect_silence\n",
    "from pydub import AudioSegment\n",
    "# function trimes silence at the beginning and at the end of audio file\n",
    "def trim_silence(input_file, output_file, silence_thresh=-40, min_silence_len=500):\n",
    "\n",
    "    audio = AudioSegment.from_file(input_file, format=\"m4a\")\n",
    "    \n",
    "    silence_ranges = detect_silence(audio, min_silence_len=min_silence_len, silence_thresh=silence_thresh)\n",
    "    \n",
    "    if silence_ranges:\n",
    "        start_trim = silence_ranges[0][1] if silence_ranges[0][0] == 0 else 0\n",
    "        end_trim = silence_ranges[-1][0] if silence_ranges[-1][1] == len(audio) else len(audio)\n",
    "        trimmed_audio = audio[start_trim:end_trim]\n",
    "    else:\n",
    "        trimmed_audio = audio  \n",
    "        \n",
    "    trimmed_audio.export(output_file, format=\"wav\")\n",
    "    print(f\"Trimmed audio saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30a3896e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed audio saved to /Users/bohdansynytskyi/Sound_Recognition/spoken_digits/test_recordings/8.wav\n",
      "Trimmed audio saved to /Users/bohdansynytskyi/Sound_Recognition/spoken_digits/test_recordings/9.wav\n",
      "Trimmed audio saved to /Users/bohdansynytskyi/Sound_Recognition/spoken_digits/test_recordings/5_2.wav\n",
      "Trimmed audio saved to /Users/bohdansynytskyi/Sound_Recognition/spoken_digits/test_recordings/4_1.wav\n",
      "Trimmed audio saved to /Users/bohdansynytskyi/Sound_Recognition/spoken_digits/test_recordings/1.wav\n",
      "Trimmed audio saved to /Users/bohdansynytskyi/Sound_Recognition/spoken_digits/test_recordings/0.wav\n",
      "Trimmed audio saved to /Users/bohdansynytskyi/Sound_Recognition/spoken_digits/test_recordings/2.wav\n",
      "Trimmed audio saved to /Users/bohdansynytskyi/Sound_Recognition/spoken_digits/test_recordings/3.wav\n",
      "Trimmed audio saved to /Users/bohdansynytskyi/Sound_Recognition/spoken_digits/test_recordings/7.wav\n",
      "Trimmed audio saved to /Users/bohdansynytskyi/Sound_Recognition/spoken_digits/test_recordings/6.wav\n",
      "Trimmed audio saved to /Users/bohdansynytskyi/Sound_Recognition/spoken_digits/test_recordings/2_2.wav\n",
      "Trimmed audio saved to /Users/bohdansynytskyi/Sound_Recognition/spoken_digits/test_recordings/4.wav\n",
      "Trimmed audio saved to /Users/bohdansynytskyi/Sound_Recognition/spoken_digits/test_recordings/5.wav\n"
     ]
    }
   ],
   "source": [
    "input_dir = '/Users/bohdansynytskyi/Sound_Recognition/spoken_digits/test_recordings'\n",
    "output_dir = '/Users/bohdansynytskyi/Sound_Recognition/spoken_digits/test_spectrograms'\n",
    "\n",
    "files = os.listdir(input_dir)\n",
    "\n",
    "for file in files:\n",
    "    if file.endswith('.m4a'):\n",
    "        audio_path = os.path.join(input_dir, file)\n",
    "        \n",
    "        wav_output_path = os.path.join(input_dir, os.path.splitext(file)[0] + '.wav')\n",
    "        trim_silence(audio_path, wav_output_path)\n",
    "        \n",
    "    \n",
    "        output_path = os.path.join(output_dir, os.path.splitext(file)[0] + '.png')\n",
    "            \n",
    "        audio_to_spectrogram(wav_output_path, output_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a5bc31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"/Users/bohdansynytskyi/Sound_Recognition/spoken_digits/test_recordings\"\n",
    "output_dir = \"/Users/bohdansynytskyi/Sound_Recognition/spoken_digits/test_spectrograms\"\n",
    "\n",
    "files = os.listdir(input_dir)\n",
    "\n",
    "for file in files:\n",
    "    if file.endswith('.wav'):\n",
    "        audio_path = os.path.join(input_dir, file)\n",
    "        save_path = os.path.join(output_dir, os.path.splitext(file)[0] + \".png\")\n",
    "        audio_to_spectrogram(audio_path, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
